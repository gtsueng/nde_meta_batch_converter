{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93c9b42",
   "metadata": {},
   "source": [
    "## Metadata spreadsheet batch converter\n",
    "\n",
    "This notebook converts metadata from a multi-tabbed spreadsheet into a json files for upload into the DDE\n",
    "\n",
    "The tabbed sheets available in the spreadsheet are as follows:\n",
    "- resource_base\n",
    "- funding\n",
    "- collectionSize\n",
    "- related\n",
    "- author\n",
    "- definedTerms\n",
    "- distribution\n",
    "\n",
    "All sheets use the url field as the index/linking field\n",
    "\n",
    "Notes:\n",
    "* resource_base: contains various metadata properties and their expected values. For citation.pmid, a helper function should be used to pull the citation name based on the pmid so that it will be able to pass the schema validation\n",
    "* funding: Note a single grant ID may be associated with multiple funding organizations. Convert 'type' to '@type'\n",
    "* related: relationship properties and their expected objects. Convert 'type' to '@type'\n",
    "* definedTerm: save only the urls to a list for the DDE\n",
    "\n",
    "How it works: \n",
    "Every sheet except for the resource_base is converted into a dictionary where the key is the url, and the value is either an array of objects (funding, collectionSize, author) or a dictionary with additional objects (related, definedTerm)\n",
    "The resource_base is converted into a base dictionary, and additional objects are added to the base dictionary using the url\n",
    "The json records are then dumped into a batch_file for upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import requests\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"your email here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = os.getcwd()\n",
    "parent_path = os.path.abspath(os.path.join(script_path, os.pardir))\n",
    "data_path = os.path.join(script_path,'data')\n",
    "filelist = os.listdir(data_path)\n",
    "result_path = os.path.join(parent_path,'nde-metadata-corrections','metadata_for_DDE','resourceCatalogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8de4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parent_path)\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde48580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rawdf(df_raw):\n",
    "    df = df_raw.fillna(-1)\n",
    "    if 'pmid' in df.columns.values.tolist():\n",
    "        df['pmid'] = df['pmid'].astype(int)\n",
    "    df.rename(columns={'type':'@type'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_nones(a_dict):\n",
    "    for k,v in list(a_dict.items()):\n",
    "        if v == -1:\n",
    "            del a_dict[k]\n",
    "        if v == \"None\":\n",
    "            del a_dict[k]\n",
    "        if v == None:\n",
    "            del a_dict[k]\n",
    "        if not isinstance(v,str) and not isinstance(v,dict) and not isinstance(v,list):\n",
    "            if isnan(v):\n",
    "                del a_dict[k]\n",
    "    return a_dict\n",
    "\n",
    "\n",
    "def clean_dict_array(dict_array):\n",
    "    for eachdict in dict_array:\n",
    "        eachdict = clean_nones(eachdict)\n",
    "    return dict_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec100bd",
   "metadata": {},
   "source": [
    "### Process the resource_base sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b956cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(df):\n",
    "    today = datetime.now()\n",
    "    df['date'] = today.strftime(\"%Y-%m-%d\")\n",
    "    return df\n",
    "\n",
    "def format_date(datefield):\n",
    "    if isinstance(datefield,str)==True:\n",
    "        cleandate = datefield\n",
    "    if isinstance(datefield,datetime)==True:\n",
    "        cleandate = datefield.strftime(\"%Y-%m-%d\")\n",
    "    return cleandate\n",
    "\n",
    "def get_pmids(citation_field):\n",
    "    citation_array = []\n",
    "    clean_citations = []\n",
    "    tmp_citations = citation_field.replace('[','').replace(']','')\n",
    "    if ',' in tmp_citations:\n",
    "        clean_citations.extend(tmp_citations.split(','))\n",
    "    else:\n",
    "        clean_citations.append(tmp_citations)\n",
    "    clean_citations = list(set(clean_citations))\n",
    "    for eachpmid in clean_citations:\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=eachpmid, rettype=\"medline\", retmode=\"text\")\n",
    "        records = Medline.parse(handle) ##parses pubmed entry for that ID and records the author\n",
    "        for record in records:\n",
    "            titles = record.get(\"TI\",\"?\") #writes the record to a list called MH \n",
    "            citation_array.append({'@type':'ScholarlyArticle',\n",
    "                                   'name':titles,\n",
    "                                   'pmid':eachpmid})\n",
    "    return citation_array\n",
    "\n",
    "def format_language(language_field):\n",
    "    language_array = []\n",
    "    if '[' in language_field:\n",
    "        tmp_lang = language_field.replace('[','').replace(']','')\n",
    "    else:\n",
    "        tmp_lang = language_field\n",
    "    if ',' in tmp_lang:\n",
    "        clean_lang = tmp_lang.split(',')\n",
    "        for eachlang in clean_lang:\n",
    "            language_array.append({'@type': 'Language','name':eachlang})\n",
    "    else:\n",
    "        language_array.append({'@type': 'Language','name':tmp_lang})\n",
    "\n",
    "    return language_array\n",
    "\n",
    "def format_usage(usage_field):\n",
    "    usage_dict = {}\n",
    "    usage_dict['@type'] = 'CreativeWork'\n",
    "    usage_dict['name'] = 'Conditions of use'\n",
    "    usage_dict['url'] = usage_field\n",
    "    return usage_dict\n",
    "\n",
    "def add_type(df):\n",
    "    df['@type'] = 'nde:ResourceCatalog'\n",
    "    return df\n",
    "\n",
    "def run_quick_clean(df):\n",
    "    ## fill the na's\n",
    "    df = df.fillna(\"None\")\n",
    "    ## format the date fields\n",
    "    dateprops = ['date','dateModified','dateCreated','datePublished']\n",
    "    for eachprop in dateprops:\n",
    "        if eachprop in list(df.columns.values):\n",
    "            df[eachprop] = df.apply(lambda row: format_date(row[eachprop]), axis=1)\n",
    "    df.drop('License type',axis=1,inplace=True)\n",
    "    ## clean up the language field\n",
    "    df['inLanguage'] = df.apply(lambda row: format_language(row['inLanguage']), axis=1)\n",
    "    ## clean up the usage info\n",
    "    df['usageInfo'] = df.apply(lambda row: format_usage(row['usageInfo']), axis=1)\n",
    "    ## clean up the citation field\n",
    "    df['citation pmid'] = df.apply(lambda row: get_pmids(row['citation pmid']), axis=1)\n",
    "    df.drop('citation pmid', axis=1, inplace=True)\n",
    "    ## clean up genre field\n",
    "    df['genre'] = df['genre'].astype(str).replace('generalist','Generalist')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(data_path,filelist[-1])\n",
    "df_base = pd.read_excel(filepath, 'resource_base', engine='openpyxl')\n",
    "df_clean = add_type(run_quick_clean(df_base))\n",
    "#print(df_samples.head(n=2))\n",
    "#print(df_samples.iloc[0]['citation pmid'])\n",
    "print(df_clean.head(n=2))\n",
    "check = df_clean.iloc[0]['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c8744",
   "metadata": {},
   "source": [
    "### process the funding sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc18453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_funder(row):\n",
    "    funder_object = {'@type':row['funder.@type'],\n",
    "                     'name':row['funder.name'],\n",
    "                     'alternateName':row['funder.alternateName'],\n",
    "                     'parentOrganization':row['funder.parentOrganization']\n",
    "                    }\n",
    "    funder_object = clean_nones(funder_object)\n",
    "    funding_object = {'@type':row['type'],\n",
    "                      'identifier': row['identifier'],\n",
    "                      'funder':funder_object\n",
    "                     }\n",
    "    return funding_object\n",
    "\n",
    "def process_multi_funders(df_funding, multi_funder_ids):\n",
    "    funder_array = []\n",
    "    for eachid in multi_funder_ids:\n",
    "        tmpdf = df_funding.loc[df_funding['identifier']==eachid]\n",
    "        cleandf = tmpdf[['funder.@type','funder.name','funder.alternateName','funder.parentOrganization']].copy()\n",
    "        cleandf.rename(columns = {'funder.@type':'@type',\n",
    "                                'funder.name':'name',\n",
    "                                'funder.alternateName':'alternateName',\n",
    "                                'funder.parentOrganization':'parentOrganization'}, inplace=True)\n",
    "        cleandf.fillna(-1,inplace=True)\n",
    "        funderlist = cleandf.to_dict(orient='records')\n",
    "        funderlist = clean_dict_array(funderlist)\n",
    "        funder_array.append({'url':tmpdf.iloc[0]['url'],'temp':{'@type':'MonetaryGrant','identifier':eachid,'funder':funderlist}})\n",
    "        funder_df = pd.DataFrame(funder_array)\n",
    "    return funder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ba8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_funding_dict(df_funding):\n",
    "    funding_dict = {}\n",
    "    funding_grouped = df_funding.groupby(['url','identifier']).size().reset_index(name='counts')\n",
    "    multi_funder_ids = funding_grouped.loc[funding_grouped['counts']>1]['identifier'].unique().tolist()\n",
    "    single_funder_ids = funding_grouped.loc[funding_grouped['counts']==1]['identifier'].unique().tolist()\n",
    "    single_funders = df_funding.loc[df_funding['identifier'].isin(single_funder_ids)].copy()\n",
    "    urllist = df_funding['url'].unique().tolist()\n",
    "    single_funders['temp'] = single_funders.apply(lambda row: process_single_funder(row), axis=1)\n",
    "    try:\n",
    "        funder_array = process_multi_funders(df_funding, multi_funder_ids)\n",
    "    except:\n",
    "        funder_array = []\n",
    "    for eachurl in urllist:\n",
    "        funding_array = []\n",
    "        ## get all single funding objects and add to array\n",
    "        clean_singles = single_funders['temp'].loc[single_funders['url']==eachurl].tolist()\n",
    "        ## add any multi funding objects to the array\n",
    "        if len(funder_array) == 0:\n",
    "            clean_multi= funder_array['temp'].loc[funder_array['url']==eachurl].tolist()\n",
    "            clean_singles.extend(clean_multi)\n",
    "        ## add the funding array to the funding_dict\n",
    "        funding_dict[eachurl]=clean_singles    \n",
    "    return funding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funding = pd.read_excel(filepath, 'funding', engine='openpyxl')\n",
    "#print(single_funders.head(n=2))\n",
    "funding_dict = generate_funding_dict(df_funding)\n",
    "print(\"sample result for: \",check)\n",
    "print(funding_dict[check])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353650a",
   "metadata": {},
   "source": [
    "### process collection_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae27d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection_dict(df_collection):\n",
    "    collection_dict = {}\n",
    "    url_list = df_collection['url'].unique().tolist()\n",
    "    df_collection['@type']='PropertyValue'\n",
    "    for eachurl in url_list:\n",
    "        tmpdf = df_collection.loc[df_collection['url']==eachurl].copy()\n",
    "        tmpdf.drop('url',inplace=True,axis=1)\n",
    "        tmp_array = tmpdf.to_dict(orient='records')\n",
    "        collection_dict[eachurl] = clean_dict_array(tmp_array)\n",
    "    return collection_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection_raw = pd.read_excel(filepath, 'collectionSize', engine='openpyxl')\n",
    "df_collection = clean_rawdf(df_collection_raw)\n",
    "collection_dict = create_collection_dict(df_collection)\n",
    "print(collection_dict[check])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7bb193",
   "metadata": {},
   "source": [
    "### process related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bda5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_urls(df):\n",
    "    url_df = df.loc[df['@type']=='URL'].copy()\n",
    "    url_list = url_df['url'].unique().tolist()\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def create_related_dict(df_related):\n",
    "    nde_dict = {\"@type\": \"DataCatalog\", \"name\": \"Data Discovery Engine\", \"url\": \"https://discovery.biothings.io/portal/nde\"}\n",
    "    related_dict = {}\n",
    "    url_list = df_related['url'].unique().tolist()\n",
    "    for eachurl in url_list:\n",
    "        prop_dict = {}\n",
    "        tmpdf = df_related.loc[df_related['url']==eachurl].copy()\n",
    "        tmpdf.drop('url', inplace=True, axis = 1)\n",
    "        tmpdf.rename(columns={'prop.url':'url'},inplace=True)\n",
    "        proplist = tmpdf['property'].tolist()\n",
    "        if 'sdPublisher' not in proplist:\n",
    "            prop_dict['sdPublisher'] = nde_dict\n",
    "        for eachprop in proplist:\n",
    "            tmpdf2 = tmpdf.loc[tmpdf['property']==eachprop].copy()\n",
    "            if 'URL' in tmpdf2['@type'].tolist():\n",
    "                tmp_array = handle_urls(tmpdf2)\n",
    "            else:\n",
    "                tmpdf2.drop('property', inplace=True, axis=1)\n",
    "                tmp_array = tmpdf2.to_dict(orient='records')\n",
    "                tmp_array = clean_dict_array(tmp_array)\n",
    "            if eachprop == 'sdPublisher':\n",
    "                tmp_array.append(nde_dict)\n",
    "            prop_dict[eachprop] = tmp_array\n",
    "        related_dict[eachurl]=prop_dict\n",
    "    return related_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_raw = pd.read_excel(filepath, 'related', engine='openpyxl')\n",
    "df_related = clean_rawdf(df_related_raw)\n",
    "#print(df_related.head(n=2))\n",
    "related_dict = create_related_dict(df_related)\n",
    "print(related_dict[check])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667876f",
   "metadata": {},
   "source": [
    "### Process the author list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_orgs(df):\n",
    "    org_df = df.copy()\n",
    "    org_df.drop(['givenName','familyName','affiliation.name'],inplace=True,axis=1)\n",
    "    org_array = org_df.to_dict(orient='records')\n",
    "    org_array = clean_dict_array(org_array)\n",
    "    return org_array\n",
    "\n",
    "def process_affiliations(an_affiliation):\n",
    "    if an_affiliation != -1:\n",
    "        tmpdict = {'@type':'Organization', 'name':an_affiliation}\n",
    "        return tmpdict\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def process_ppl(df):\n",
    "    ppl_df = df.copy()\n",
    "    ppl_df['affiliation'] = ppl_df.apply(lambda row: process_affiliations(row['affiliation.name']),axis=1)\n",
    "    ppl_df.drop(['parentOrganization','affiliation.name'],inplace=True,axis=1)\n",
    "    ppl_array = ppl_df.to_dict(orient='records')\n",
    "    ppl_array = clean_dict_array(ppl_array)\n",
    "    return ppl_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59936d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author_dict(df_author):\n",
    "    author_dict = {}\n",
    "    urlist = df_author['url'].unique().tolist()\n",
    "    for eachurl in urlist:\n",
    "        author_array = []\n",
    "        tmpdf = df_author.loc[df_author['url']==eachurl].copy()\n",
    "        tmpdf.drop('url',inplace=True,axis=1)\n",
    "        if 'Organization' in tmpdf['@type'].tolist():\n",
    "            orgdf = tmpdf.loc[tmpdf['@type']=='Organization']\n",
    "            org_array = process_orgs(orgdf)\n",
    "            author_array.extend(org_array)\n",
    "        if 'Person' in tmpdf['@type'].tolist():\n",
    "            ppldf = tmpdf.loc[tmpdf['@type']=='Person']\n",
    "            ppl_array = process_ppl(ppldf)\n",
    "            author_array.extend(ppl_array)\n",
    "        author_dict[eachurl] = author_array\n",
    "    return author_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba06e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_author_raw = pd.read_excel(filepath, 'author', engine='openpyxl')\n",
    "df_author = clean_rawdf(df_author_raw)\n",
    "author_dict = create_author_dict(df_author)\n",
    "print(author_dict[check])\n",
    "#print(df_author.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a96d5b",
   "metadata": {},
   "source": [
    "### Process the definedTerms sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dt_dict(df_dt):\n",
    "    dfdt_dict={}\n",
    "    urlist = df_dt['url'].tolist()\n",
    "    for eachurl in urlist:\n",
    "        prop_dict={}\n",
    "        tmpdf = df_dt.loc[df_dt['url']==eachurl].copy()\n",
    "        tmpdf.drop('url',inplace=True,axis=1)\n",
    "        proplist = tmpdf['property'].unique().tolist()\n",
    "        for eachprop in proplist:\n",
    "            prop_dict[eachprop]=tmpdf.loc[tmpdf['property']==eachprop]['prop.url'].unique().tolist()\n",
    "        dfdt_dict[eachurl]=prop_dict\n",
    "    return dfdt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_definedTerm_raw = pd.read_excel(filepath, 'definedTerms', engine='openpyxl')\n",
    "df_dt = clean_rawdf(df_definedTerm_raw)\n",
    "dfdt_dict = generate_dt_dict(df_dt)\n",
    "#print(df_dt.head(n=2))\n",
    "print(dfdt_dict[check])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c56f3",
   "metadata": {},
   "source": [
    "### Process the distribution sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distro_dict(df):\n",
    "    distro_dict = {}\n",
    "    if len(df) !=0:\n",
    "        df['dateModified'] = df.apply(lambda row: format_date(row['dateModified']),axis=1)\n",
    "        urlist = df['url'].unique().tolist()\n",
    "        for eachurl in urlist:\n",
    "            tmpdf = df.loc[df['url']==eachurl].copy()\n",
    "            tmpdf.drop('url',inplace=True,axis=1)\n",
    "            tmp_array = tmpdf.to_dict(orient='records')\n",
    "            tmp_array = clean_dict_array(tmp_array)\n",
    "            distro_dict[eachurl]=tmp_array\n",
    "    return distro_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf770a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distro_raw = pd.read_excel(filepath, 'distribution', engine='openpyxl')\n",
    "df_distro = clean_rawdf(df_distro_raw)\n",
    "distro_dict = create_distro_dict(df_distro)\n",
    "\n",
    "try:\n",
    "    print(distro_dict[check])\n",
    "except:\n",
    "    print(\"no distro data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a85110",
   "metadata": {},
   "source": [
    "### Assemble the json records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a298bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_records(filepath,context_dict):\n",
    "    batchlist = []\n",
    "    df_base = pd.read_excel(filepath, 'resource_base', engine='openpyxl')\n",
    "    df_clean = add_type(run_quick_clean(df_base))\n",
    "    today = datetime.now()\n",
    "    df_clean['date'] = today.strftime(\"%Y-%m-%d\")\n",
    "    df_funding = pd.read_excel(filepath, 'funding', engine='openpyxl')\n",
    "    funding_dict = generate_funding_dict(df_funding)\n",
    "    df_collection_raw = pd.read_excel(filepath, 'collectionSize', engine='openpyxl')\n",
    "    df_collection = clean_rawdf(df_collection_raw)\n",
    "    collection_dict = create_collection_dict(df_collection)\n",
    "    df_related_raw = pd.read_excel(filepath, 'related', engine='openpyxl')\n",
    "    df_related = clean_rawdf(df_related_raw)\n",
    "    related_dict = create_related_dict(df_related)\n",
    "    df_author_raw = pd.read_excel(filepath, 'author', engine='openpyxl')\n",
    "    df_author = clean_rawdf(df_author_raw)\n",
    "    author_dict = create_author_dict(df_author)\n",
    "    df_definedTerm_raw = pd.read_excel(filepath, 'definedTerms', engine='openpyxl')\n",
    "    df_dt = clean_rawdf(df_definedTerm_raw)\n",
    "    dfdt_dict = generate_dt_dict(df_dt)\n",
    "    df_distro_raw = pd.read_excel(filepath, 'distribution', engine='openpyxl')\n",
    "    df_distro = clean_rawdf(df_distro_raw)\n",
    "    distro_dict = create_distro_dict(df_distro)\n",
    "    base_dict_array = df_clean.to_dict(orient='records')\n",
    "    base_dict_array = clean_dict_array(base_dict_array)\n",
    "    for eachdict in base_dict_array:\n",
    "        url = eachdict['url']\n",
    "        eachdict['@context'] = context_dict\n",
    "        eachdict['funding'] = funding_dict[url]\n",
    "        eachdict['author'] = author_dict[url]\n",
    "        try:\n",
    "            eachdict['collectionSize'] = collection_dict[url]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            eachdict['distribution'] = distro_dict[url]\n",
    "        except:\n",
    "            pass\n",
    "        eachdict.update(related_dict[url])\n",
    "        eachdict.update(dfdt_dict[url])\n",
    "        batchlist.append(eachdict)\n",
    "    return batchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a64a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dict = {\"owl\": \"http://www.w3.org/2002/07/owl#\",\n",
    "                      \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "                      \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "                      \"schema\": \"http://schema.org/\",\n",
    "                      \"niaid\": \"https://discovery.biothings.io/view/niaid/\",\n",
    "                      \"nde\": \"https://discovery.biothings.io/view/nde/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchlist = process_records(filepath,context_dict)\n",
    "today = datetime.now()\n",
    "with open(os.path.join(result_path,f'{today.strftime(\"%Y-%m-%d\")}_batch_file.json'),'w') as outfile:\n",
    "    outfile.write(json.dumps(batchlist, indent=4))\n",
    "print(batchlist[0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80c5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c03bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2083cca",
   "metadata": {},
   "source": [
    "### test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d86be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_dict = {}\n",
    "funding_grouped = df_funding.groupby(['url','identifier']).size().reset_index(name='counts')\n",
    "multi_funder_ids = funding_grouped.loc[funding_grouped['counts']>1]['identifier'].unique().tolist()\n",
    "single_funder_ids = funding_grouped.loc[funding_grouped['counts']==1]['identifier'].unique().tolist()\n",
    "single_funders = df_funding.loc[df_funding['identifier'].isin(single_funder_ids)].copy()\n",
    "urllist = df_funding['url'].unique().tolist()\n",
    "single_funders['temp'] = single_funders.apply(lambda row: process_single_funder(row), axis=1)\n",
    "funder_array = process_multi_funders(df_funding, multi_funder_ids)\n",
    "for eachurl in urllist:\n",
    "    funding_array = []\n",
    "    ## get all single funding objects and add to array\n",
    "    clean_singles = single_funders['temp'].loc[single_funders['url']==eachurl].tolist()\n",
    "    ## add any multi funding objects to the array\n",
    "    clean_multi= funder_array['temp'].loc[funder_array['url']==eachurl].tolist()\n",
    "    clean_singles.extend(clean_multi)\n",
    "    ## add the funding array to the funding_dict\n",
    "    funding_dict[eachurl]=clean_singles\n",
    "\n",
    "print(funding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f36cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
