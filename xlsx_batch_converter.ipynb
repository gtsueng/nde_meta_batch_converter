{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93c9b42",
   "metadata": {},
   "source": [
    "## Metadata spreadsheet batch converter\n",
    "\n",
    "This notebook converts metadata from a multi-tabbed spreadsheet into a json files for upload into the DDE\n",
    "\n",
    "The tabbed sheets available in the spreadsheet are as follows:\n",
    "- resource_base\n",
    "- funding\n",
    "- collectionSize\n",
    "- related\n",
    "- author\n",
    "- definedTerms\n",
    "- distribution\n",
    "\n",
    "All sheets use the url field as the index/linking field\n",
    "\n",
    "Notes:\n",
    "* resource_base: contains various metadata properties and their expected values. For citation.pmid, a helper function should be used to pull the citation name based on the pmid so that it will be able to pass the schema validation\n",
    "* funding: Note a single grant ID may be associated with multiple funding organizations. Convert 'type' to '@type'\n",
    "* related: relationship properties and their expected objects. Convert 'type' to '@type'\n",
    "* definedTerm: save only the urls to a list for the DDE\n",
    "\n",
    "How it works: \n",
    "Every sheet except for the resource_base is converted into a dictionary where the key is the url, and the value is either an array of objects (funding, collectionSize, author) or a dictionary with additional objects (related, definedTerm)\n",
    "The resource_base is converted into a base dictionary, and additional objects are added to the base dictionary using the url\n",
    "The json records are then dumped into a batch_file for upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cfe727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import requests\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c48863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"your email here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10f5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = os.getcwd()\n",
    "parent_path = os.path.abspath(os.path.join(script_path, os.pardir))\n",
    "data_path = os.path.join(script_path,'data')\n",
    "filelist = os.listdir(data_path)\n",
    "result_path = os.path.join(parent_path,'nde-metadata-corrections','metadata_for_DDE','resourceCatalogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab8de4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\nde\n",
      "['2024_05_14_RepoMetaCuration.xlsx', '2024_05_21_RepoMetaCuration.xlsx', '2024_06_18_RepoMetaCuration.xlsx', '~$2024_06_18_RepoMetaCuration.xlsx']\n"
     ]
    }
   ],
   "source": [
    "print(parent_path)\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde48580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rawdf(df_raw):\n",
    "    df = df_raw.fillna(-1)\n",
    "    if 'pmid' in df.columns.values.tolist():\n",
    "        df['pmid'] = df['pmid'].astype(int)\n",
    "    df.rename(columns={'type':'@type'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_nones(a_dict):\n",
    "    for k,v in list(a_dict.items()):\n",
    "        if v == -1:\n",
    "            del a_dict[k]\n",
    "        if v == \"None\":\n",
    "            del a_dict[k]\n",
    "        if v == None:\n",
    "            del a_dict[k]\n",
    "        if not isinstance(v,str) and not isinstance(v,dict) and not isinstance(v,list):\n",
    "            if isnan(v):\n",
    "                del a_dict[k]\n",
    "    return a_dict\n",
    "\n",
    "\n",
    "def clean_dict_array(dict_array):\n",
    "    for eachdict in dict_array:\n",
    "        eachdict = clean_nones(eachdict)\n",
    "    return dict_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec100bd",
   "metadata": {},
   "source": [
    "### Process the resource_base sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b956cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(df):\n",
    "    today = datetime.now()\n",
    "    df['date'] = today.strftime(\"%Y-%m-%d\")\n",
    "    return df\n",
    "\n",
    "def format_date(datefield):\n",
    "    if isinstance(datefield,str)==True:\n",
    "        cleandate = datefield\n",
    "    if isinstance(datefield,datetime)==True:\n",
    "        cleandate = datefield.strftime(\"%Y-%m-%d\")\n",
    "    return cleandate\n",
    "\n",
    "def get_pmids(citation_field):\n",
    "    citation_array = []\n",
    "    clean_citations = []\n",
    "    tmp_citations = citation_field.replace('[','').replace(']','')\n",
    "    if ',' in tmp_citations:\n",
    "        clean_citations.extend(tmp_citations.split(','))\n",
    "    else:\n",
    "        clean_citations.append(tmp_citations)\n",
    "    clean_citations = list(set(clean_citations))\n",
    "    for eachpmid in clean_citations:\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=eachpmid, rettype=\"medline\", retmode=\"text\")\n",
    "        records = Medline.parse(handle) ##parses pubmed entry for that ID and records the author\n",
    "        for record in records:\n",
    "            titles = record.get(\"TI\",\"?\") #writes the record to a list called MH \n",
    "            citation_array.append({'@type':'ScholarlyArticle',\n",
    "                                   'name':titles,\n",
    "                                   'pmid':eachpmid})\n",
    "    return citation_array\n",
    "\n",
    "def format_language(language_field):\n",
    "    language_array = []\n",
    "    if '[' in language_field:\n",
    "        tmp_lang = language_field.replace('[','').replace(']','')\n",
    "    else:\n",
    "        tmp_lang = language_field\n",
    "    if ',' in tmp_lang:\n",
    "        clean_lang = tmp_lang.split(',')\n",
    "        for eachlang in clean_lang:\n",
    "            language_array.append({'@type': 'Language','name':eachlang})\n",
    "    else:\n",
    "        language_array.append({'@type': 'Language','name':tmp_lang})\n",
    "\n",
    "    return language_array\n",
    "\n",
    "def format_usage(usage_field):\n",
    "    usage_dict = {}\n",
    "    usage_dict['@type'] = 'CreativeWork'\n",
    "    usage_dict['name'] = 'Conditions of use'\n",
    "    usage_dict['url'] = usage_field\n",
    "    return usage_dict\n",
    "\n",
    "def add_type(df):\n",
    "    df['@type'] = 'nde:ResourceCatalog'\n",
    "    return df\n",
    "\n",
    "def run_quick_clean(df):\n",
    "    ## fill the na's\n",
    "    df = df.fillna(\"None\")\n",
    "    ## format the date fields\n",
    "    dateprops = ['date','dateModified','dateCreated','datePublished']\n",
    "    for eachprop in dateprops:\n",
    "        if eachprop in list(df.columns.values):\n",
    "            df[eachprop] = df.apply(lambda row: format_date(row[eachprop]), axis=1)\n",
    "    df.drop('License type',axis=1,inplace=True)\n",
    "    ## clean up the language field\n",
    "    df['inLanguage'] = df.apply(lambda row: format_language(row['inLanguage']), axis=1)\n",
    "    ## clean up the usage info\n",
    "    df['usageInfo'] = df.apply(lambda row: format_usage(row['usageInfo']), axis=1)\n",
    "    ## clean up the citation field\n",
    "    df['citation pmid'] = df.apply(lambda row: get_pmids(row['citation pmid']), axis=1)\n",
    "    df.drop('citation pmid', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecc07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name                    url             identifier alternateName  \\\n",
      "0  WormBase  https://wormbase.org/  https://wormbase.org/          None   \n",
      "1   FlyBase   https://flybase.org/   https://flybase.org/          None   \n",
      "\n",
      "                                          license conditionsOfAccess  \\\n",
      "0  https://creativecommons.org/public-domain/cc0/               Open   \n",
      "1    https://creativecommons.org/licenses/by/4.0/               Open   \n",
      "\n",
      "                                           usageInfo  \\\n",
      "0  {'@type': 'CreativeWork', 'name': 'Conditions ...   \n",
      "1  {'@type': 'CreativeWork', 'name': 'Conditions ...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  WormBase is a NIH supported biomedical reposit...   \n",
      "1  FlyBase is a NIH supported basic science repos...   \n",
      "\n",
      "                                         description  collectionType  hasAPI  \\\n",
      "0  WormBase is an international consortium of bio...  Knowledge base    True   \n",
      "1  The aim of the FlyBase project is to provide a...  Knowledge base   False   \n",
      "\n",
      "   hasDownload  isAccessibleForFree  \\\n",
      "0  All content                 True   \n",
      "1  All content                 True   \n",
      "\n",
      "                                   inLanguage    version          genre  \\\n",
      "0  [{'@type': 'Language', 'name': 'English'}]      WS292     Biomedical   \n",
      "1  [{'@type': 'Language', 'name': 'English'}]  FB2024_02  Basic science   \n",
      "\n",
      "  dateModified dateCreated datePublished                @type  \n",
      "0   2024-03-29  1998-09-01    2000-12-13  nde:ResourceCatalog  \n",
      "1   2024-04-23        None    1994-07-01  nde:ResourceCatalog  \n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(data_path,filelist[2])\n",
    "df_base = pd.read_excel(filepath, 'resource_base', engine='openpyxl')\n",
    "df_clean = add_type(run_quick_clean(df_base))\n",
    "#print(df_samples.head(n=2))\n",
    "#print(df_samples.iloc[0]['citation pmid'])\n",
    "print(df_clean.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c8744",
   "metadata": {},
   "source": [
    "### process the funding sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc18453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_funder(row):\n",
    "    funder_object = {'@type':row['funder.@type'],\n",
    "                     'name':row['funder.name'],\n",
    "                     'alternateName':row['funder.alternateName'],\n",
    "                     'parentOrganization':row['funder.parentOrganization']\n",
    "                    }\n",
    "    funder_object = clean_nones(funder_object)\n",
    "    funding_object = {'@type':row['type'],\n",
    "                      'identifier': row['identifier'],\n",
    "                      'funder':funder_object\n",
    "                     }\n",
    "    return funding_object\n",
    "\n",
    "def process_multi_funders(df_funding, multi_funder_ids):\n",
    "    funder_array = []\n",
    "    for eachid in multi_funder_ids:\n",
    "        tmpdf = df_funding.loc[df_funding['identifier']==eachid]\n",
    "        cleandf = tmpdf[['funder.@type','funder.name','funder.alternateName','funder.parentOrganization']].copy()\n",
    "        cleandf.rename(columns = {'funder.@type':'@type',\n",
    "                                'funder.name':'name',\n",
    "                                'funder.alternateName':'alternateName',\n",
    "                                'funder.parentOrganization':'parentOrganization'}, inplace=True)\n",
    "        cleandf.fillna(-1,inplace=True)\n",
    "        funderlist = cleandf.to_dict(orient='records')\n",
    "        funderlist = clean_dict_array(funderlist)\n",
    "        funder_array.append({'url':tmpdf.iloc[0]['url'],'temp':{'@type':'MonetaryGrant','identifier':eachid,'funder':funderlist}})\n",
    "        funder_df = pd.DataFrame(funder_array)\n",
    "    return funder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9ba8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_funding_dict(df_funding):\n",
    "    funding_dict = {}\n",
    "    funding_grouped = df_funding.groupby(['url','identifier']).size().reset_index(name='counts')\n",
    "    multi_funder_ids = funding_grouped.loc[funding_grouped['counts']>1]['identifier'].unique().tolist()\n",
    "    single_funder_ids = funding_grouped.loc[funding_grouped['counts']==1]['identifier'].unique().tolist()\n",
    "    single_funders = df_funding.loc[df_funding['identifier'].isin(single_funder_ids)].copy()\n",
    "    urllist = df_funding['url'].unique().tolist()\n",
    "    single_funders['temp'] = single_funders.apply(lambda row: process_single_funder(row), axis=1)\n",
    "    funder_array = process_multi_funders(df_funding, multi_funder_ids)\n",
    "    for eachurl in urllist:\n",
    "        funding_array = []\n",
    "        ## get all single funding objects and add to array\n",
    "        clean_singles = single_funders['temp'].loc[single_funders['url']==eachurl].tolist()\n",
    "        ## add any multi funding objects to the array\n",
    "        clean_multi= funder_array['temp'].loc[funder_array['url']==eachurl].tolist()\n",
    "        clean_singles.extend(clean_multi)\n",
    "        ## add the funding array to the funding_dict\n",
    "        funding_dict[eachurl]=clean_singles    \n",
    "    return funding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c701bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'@type': 'MonetaryGrant', 'identifier': 'U24HG013300', 'funder': {'@type': 'Organization', 'name': 'National Human Genome Research Institute', 'alternateName': 'NHGRI', 'parentOrganization': 'NIH'}}, {'@type': 'MonetaryGrant', 'identifier': 'MR/W024233/1', 'funder': {'@type': 'Organization', 'name': 'UK Medical Research Council', 'alternateName': 'MRC', 'parentOrganization': 'UKRI'}}, {'@type': 'MonetaryGrant', 'identifier': 2035515, 'funder': {'@type': 'Organization', 'name': 'National Science Foundation', 'alternateName': 'NSF'}}, {'@type': 'MonetaryGrant', 'identifier': 'BB/T014008/1', 'funder': {'@type': 'Organization', 'name': 'Biotechnology and Biological Sciences Research Council', 'alternateName': 'BBSRC', 'parentOrganization': 'UKRI'}}, {'@type': 'MonetaryGrant', 'identifier': 'PLM13398', 'funder': {'@type': 'Organization', 'name': 'Wellcome Trust'}}, {'@type': 'MonetaryGrant', 'identifier': 2039324, 'funder': {'@type': 'Organization', 'name': 'National Science Foundation', 'alternateName': 'NSF'}}, {'@type': 'MonetaryGrant', 'identifier': 'U24HG010859', 'funder': {'@type': 'Organization', 'name': 'National Human Genome Research Institute', 'alternateName': 'NHGRI', 'parentOrganization': 'NIH'}}, {'@type': 'MonetaryGrant', 'identifier': '1R01DK136945-01', 'funder': {'@type': 'Organization', 'name': 'National Institute of Diabetes and Digestive and Kidney Diseases', 'alternateName': 'NIDDK', 'parentOrganization': 'NIH'}}, {'@type': 'MonetaryGrant', 'identifier': 'U24HG010859', 'funder': [{'@type': 'Organization', 'name': 'National Human Genome Research Institute', 'alternateName': 'NHGRI', 'parentOrganization': 'NIH'}, {'@type': 'Organization', 'name': 'National Human Genome Research Institute', 'alternateName': 'NHGRI', 'parentOrganization': 'NIH'}, {'@type': 'Organization', 'name': 'National Heart, Lung, and Blood Institute', 'alternateName': 'NHLBI', 'parentOrganization': 'NIH'}]}]\n"
     ]
    }
   ],
   "source": [
    "df_funding = pd.read_excel(filepath, 'funding', engine='openpyxl')\n",
    "#print(single_funders.head(n=2))\n",
    "funding_dict = generate_funding_dict(df_funding)\n",
    "print(funding_dict['https://flybase.org/'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353650a",
   "metadata": {},
   "source": [
    "### process collection_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae27d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection_dict(df_collection):\n",
    "    collection_dict = {}\n",
    "    url_list = df_collection['url'].unique().tolist()\n",
    "    df_collection['@type']='PropertyValue'\n",
    "    for eachurl in url_list:\n",
    "        tmpdf = df_collection.loc[df_collection['url']==eachurl].copy()\n",
    "        tmpdf.drop('url',inplace=True,axis=1)\n",
    "        tmp_array = tmpdf.to_dict(orient='records')\n",
    "        collection_dict[eachurl] = clean_dict_array(tmp_array)\n",
    "    return collection_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50c0869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'minValue': 19984, 'unitText': 'Protein-coding genes', '@type': 'PropertyValue'}, {'minValue': 27668, 'unitText': 'Non-coding RNA and pseudogene', '@type': 'PropertyValue'}, {'minValue': 1523, 'unitText': 'Uncloned genes', '@type': 'PropertyValue'}, {'minValue': 28587, 'unitText': 'CDS', '@type': 'PropertyValue'}, {'minValue': 19981, 'unitText': 'protein-coding loci', '@type': 'PropertyValue'}, {'minValue': 28587, 'unitText': 'sequences', '@type': 'PropertyValue'}]\n"
     ]
    }
   ],
   "source": [
    "df_collection_raw = pd.read_excel(filepath, 'collectionSize', engine='openpyxl')\n",
    "df_collection = clean_rawdf(df_collection_raw)\n",
    "collection_dict = create_collection_dict(df_collection)\n",
    "print(collection_dict['https://wormbase.org/'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7bb193",
   "metadata": {},
   "source": [
    "### process related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46bda5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_urls(df):\n",
    "    url_df = df.loc[df['@type']=='URL'].copy()\n",
    "    url_list = url_df['url'].unique().tolist()\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def create_related_dict(df_related):\n",
    "    nde_dict = {\"@type\": \"DataCatalog\", \"name\": \"Data Discovery Engine\", \"url\": \"https://discovery.biothings.io/portal/nde\"}\n",
    "    related_dict = {}\n",
    "    url_list = df_related['url'].unique().tolist()\n",
    "    for eachurl in url_list:\n",
    "        prop_dict = {}\n",
    "        tmpdf = df_related.loc[df_related['url']==eachurl].copy()\n",
    "        tmpdf.drop('url', inplace=True, axis = 1)\n",
    "        tmpdf.rename(columns={'prop.url':'url'},inplace=True)\n",
    "        proplist = tmpdf['property'].tolist()\n",
    "        if 'sdPublisher' not in proplist:\n",
    "            prop_dict['sdPublisher'] = nde_dict\n",
    "        for eachprop in proplist:\n",
    "            tmpdf2 = tmpdf.loc[tmpdf['property']==eachprop].copy()\n",
    "            if 'URL' in tmpdf2['@type'].tolist():\n",
    "                tmp_array = handle_urls(tmpdf2)\n",
    "            else:\n",
    "                tmpdf2.drop('property', inplace=True, axis=1)\n",
    "                tmp_array = tmpdf2.to_dict(orient='records')\n",
    "                tmp_array = clean_dict_array(tmp_array)\n",
    "            if eachprop == 'sdPublisher':\n",
    "                tmp_array.append(nde_dict)\n",
    "            prop_dict[eachprop] = tmp_array\n",
    "        related_dict[eachurl]=prop_dict\n",
    "    return related_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1600741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hasPart': [{'@type': 'ComputationalTool', 'name': 'Wormicloud', 'url': 'https://wormicloud.textpressolab.com/'}, {'@type': 'SoftwareSourceCode', 'name': 'Vennter', 'url': 'https://github.com/WormBase/website-public/releases/tag/WS276.1'}], 'isBasedOn': [{'@type': 'ScholarlyArticle', 'name': 'Tissue enrichment analysis for C. elegans genomics', 'url': 'https://pubmed.ncbi.nlm.nih.gov/27618863/', 'pmid': 27618863, 'doi': '10.1186/s12859-016-1229-9'}, {'@type': 'CreativeWork', 'name': 'Worm Phenotype Ontology', 'url': 'http://purl.obolibrary.org/obo/wbphenotype.owl'}, {'@type': 'SoftwareSourceCode', 'name': 'Wormbase code repositories', 'url': 'https://github.com/WormBase'}], 'isBasisFor': [{'@type': 'CreativeWork', 'name': 'Worm Phenotype Ontology', 'url': 'http://purl.obolibrary.org/obo/wbphenotype.owl'}, {'@type': 'ResourceCatalog', 'name': 'WormBase ParaSite', 'url': 'https://parasite.wormbase.org/index.html'}], 'citedBy': [{'@type': 'ScholarlyArticle', 'name': 'Worm Phenotype Ontology: Integrating phenotype data within and beyond the C. elegans community', 'pmid': 21261995, 'doi': '10.1186/1471-2105-12-32'}], 'isPartOf': [{'@type': 'ResourceCatalog', 'name': 'Alliance of Genome Resources', 'url': 'https://www.alliancegenome.org/'}], 'sdPublisher': [{'@type': 'DataCatalog', 'name': 'Fairsharing.org', 'url': 'https://fairsharing.org/FAIRsharing.zx1td8'}, {'@type': 'DataCatalog', 'name': 're3data.org', 'url': 'https://www.re3data.org/repository/r3d100010424'}, {'@type': 'DataCatalog', 'name': 'Data Discovery Engine', 'url': 'https://discovery.biothings.io/portal/nde'}], 'sameAs': ['https://www.wikidata.org/wiki/Q3570042']}\n"
     ]
    }
   ],
   "source": [
    "df_related_raw = pd.read_excel(filepath, 'related', engine='openpyxl')\n",
    "df_related = clean_rawdf(df_related_raw)\n",
    "#print(df_related.head(n=2))\n",
    "related_dict = create_related_dict(df_related)\n",
    "print(related_dict['https://wormbase.org/'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667876f",
   "metadata": {},
   "source": [
    "### Process the author list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9bdbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_orgs(df):\n",
    "    org_df = df.copy()\n",
    "    org_df.drop(['givenName','familyName','affiliation.name'],inplace=True,axis=1)\n",
    "    org_array = org_df.to_dict(orient='records')\n",
    "    org_array = clean_dict_array(org_array)\n",
    "    return org_array\n",
    "\n",
    "def process_affiliations(an_affiliation):\n",
    "    if an_affiliation != -1:\n",
    "        tmpdict = {'@type':'Organization', 'name':an_affiliation}\n",
    "        return tmpdict\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def process_ppl(df):\n",
    "    ppl_df = df.copy()\n",
    "    ppl_df['affiliation'] = ppl_df.apply(lambda row: process_affiliations(row['affiliation.name']),axis=1)\n",
    "    ppl_df.drop(['parentOrganization','affiliation.name'],inplace=True,axis=1)\n",
    "    ppl_array = ppl_df.to_dict(orient='records')\n",
    "    ppl_array = clean_dict_array(ppl_array)\n",
    "    return ppl_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59936d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author_dict(df_author):\n",
    "    author_dict = {}\n",
    "    urlist = df_author['url'].unique().tolist()\n",
    "    for eachurl in urlist:\n",
    "        author_array = []\n",
    "        tmpdf = df_author.loc[df_author['url']==eachurl].copy()\n",
    "        tmpdf.drop('url',inplace=True,axis=1)\n",
    "        if 'Organization' in tmpdf['@type'].tolist():\n",
    "            orgdf = tmpdf.loc[tmpdf['@type']=='Organization']\n",
    "            org_array = process_orgs(orgdf)\n",
    "            author_array.extend(org_array)\n",
    "        if 'Person' in tmpdf['@type'].tolist():\n",
    "            ppldf = tmpdf.loc[tmpdf['@type']=='Person']\n",
    "            ppl_array = process_ppl(ppldf)\n",
    "            author_array.extend(ppl_array)\n",
    "        author_dict[eachurl] = author_array\n",
    "    return author_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba06e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'@type': 'Organization', 'name': 'California Institute of Technology', 'alternateName': 'CalTech'}, {'@type': 'Organization', 'name': 'Wellcome Trust Sanger Institute ', 'alternateName': 'WTSI'}, {'@type': 'Organization', 'name': 'European Bioinformatics Institute', 'alternateName': 'EBI'}, {'@type': 'Organization', 'name': 'Ontario Institute for Cancer Research ', 'alternateName': 'OICR'}, {'@type': 'Organization', 'name': 'Washington University at St. Louis ', 'alternateName': 'WUSTL'}, {'@type': 'Organization', 'name': 'The WormBase Consortium'}, {'@type': 'Person', 'name': 'Paul Sternberg', 'givenName': 'Paul', 'familyName': 'Sternberg', 'affiliation': {'@type': 'Organization', 'name': 'California Institute of Technology'}}, {'@type': 'Person', 'name': 'Matt Berriman', 'givenName': 'Matt', 'familyName': 'Berriman', 'affiliation': {'@type': 'Organization', 'name': 'Wellcome Trust Sanger Institute '}}, {'@type': 'Person', 'name': 'Sarah Dyer', 'givenName': 'Sarah', 'familyName': 'Dyer', 'affiliation': {'@type': 'Organization', 'name': 'European Bioinformatics Institute'}}, {'@type': 'Person', 'name': 'Lincoln Stein', 'givenName': 'Lincoln', 'familyName': 'Stein', 'affiliation': {'@type': 'Organization', 'name': 'Ontario Institute for Cancer Research '}}]\n"
     ]
    }
   ],
   "source": [
    "df_author_raw = pd.read_excel(filepath, 'author', engine='openpyxl')\n",
    "df_author = clean_rawdf(df_author_raw)\n",
    "author_dict = create_author_dict(df_author)\n",
    "print(author_dict['https://wormbase.org/'])\n",
    "#print(df_author.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a96d5b",
   "metadata": {},
   "source": [
    "### Process the definedTerms sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbb9d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dt_dict(df_dt):\n",
    "    dfdt_dict={}\n",
    "    urlist = df_dt['url'].tolist()\n",
    "    for eachurl in urlist:\n",
    "        prop_dict={}\n",
    "        tmpdf = df_dt.loc[df_dt['url']==eachurl].copy()\n",
    "        tmpdf.drop('url',inplace=True,axis=1)\n",
    "        proplist = tmpdf['property'].unique().tolist()\n",
    "        for eachprop in proplist:\n",
    "            prop_dict[eachprop]=tmpdf.loc[tmpdf['property']==eachprop]['prop.url'].unique().tolist()\n",
    "        dfdt_dict[eachurl]=prop_dict\n",
    "    return dfdt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "281e5267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'species': ['http://purl.obolibrary.org/obo/NCBITaxon_6239', 'http://purl.obolibrary.org/obo/NCBITaxon_135651', 'http://purl.obolibrary.org/obo/NCBITaxon_281687', 'http://purl.obolibrary.org/obo/NCBITaxon_31234', 'http://purl.obolibrary.org/obo/NCBITaxon_54126'], 'infectiousAgent': ['http://purl.obolibrary.org/obo/NCBITaxon_6279', 'http://purl.obolibrary.org/obo/NCBITaxon_6282', 'http://purl.obolibrary.org/obo/NCBITaxon_34506', 'http://purl.obolibrary.org/obo/NCBITaxon_70415'], 'topicCategory': ['http://edamontology.org/topic_0621', 'http://edamontology.org/topic_3053', 'http://edamontology.org/topic_0622'], 'keywords': ['http://purl.obolibrary.org/obo/NCIT_C48292', 'http://edamontology.org/topic_0625', 'http://edamontology.org/topic_3067'], 'healthCondition': ['http://purl.obolibrary.org/obo/MONDO_0005761', 'http://purl.obolibrary.org/obo/MONDO_0017137'], 'measurementTechnique': ['http://edamontology.org/operation_0226', 'http://purl.obolibrary.org/obo/OBI_0002628', 'http://purl.obolibrary.org/obo/NCIT_C48292'], 'variableMeasured': ['http://purl.obolibrary.org/obo/NCIT_C48933', 'http://purl.obolibrary.org/obo/NCIT_C16977', 'http://purl.obolibrary.org/obo/NCIT_C44272']}\n"
     ]
    }
   ],
   "source": [
    "df_definedTerm_raw = pd.read_excel(filepath, 'definedTerms', engine='openpyxl')\n",
    "df_dt = clean_rawdf(df_definedTerm_raw)\n",
    "dfdt_dict = generate_dt_dict(df_dt)\n",
    "#print(df_dt.head(n=2))\n",
    "print(dfdt_dict['https://wormbase.org/'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c56f3",
   "metadata": {},
   "source": [
    "### Process the distribution sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1815873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distro_dict(df):\n",
    "    distro_dict = {}\n",
    "    df['dateModified'] = df.apply(lambda row: format_date(row['dateModified']),axis=1)\n",
    "    urlist = df['url'].unique().tolist()\n",
    "    for eachurl in urlist:\n",
    "        tmpdf = df.loc[df['url']==eachurl].copy()\n",
    "        tmpdf.drop('url',inplace=True,axis=1)\n",
    "        tmp_array = tmpdf.to_dict(orient='records')\n",
    "        tmp_array = clean_dict_array(tmp_array)\n",
    "        distro_dict[eachurl]=tmp_array\n",
    "    return distro_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf770a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'@type': 'DataDownload', 'contentUrl': 'ftp.wormbase.org/pub/wormbase/releases', 'dateModified': '2024-03-29'}]\n"
     ]
    }
   ],
   "source": [
    "df_distro_raw = pd.read_excel(filepath, 'distribution', engine='openpyxl')\n",
    "df_distro = clean_rawdf(df_distro_raw)\n",
    "distro_dict = create_distro_dict(df_distro)\n",
    "\n",
    "print(distro_dict['https://wormbase.org/'])\n",
    "#print(df_distro.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a85110",
   "metadata": {},
   "source": [
    "### Assemble the json records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a298bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_records(filepath,context_dict):\n",
    "    batchlist = []\n",
    "    df_base = pd.read_excel(filepath, 'resource_base', engine='openpyxl')\n",
    "    df_clean = add_type(run_quick_clean(df_base))\n",
    "    today = datetime.now()\n",
    "    df_clean['date'] = today.strftime(\"%Y-%m-%d\")\n",
    "    df_funding = pd.read_excel(filepath, 'funding', engine='openpyxl')\n",
    "    funding_dict = generate_funding_dict(df_funding)\n",
    "    df_collection_raw = pd.read_excel(filepath, 'collectionSize', engine='openpyxl')\n",
    "    df_collection = clean_rawdf(df_collection_raw)\n",
    "    collection_dict = create_collection_dict(df_collection)\n",
    "    df_related_raw = pd.read_excel(filepath, 'related', engine='openpyxl')\n",
    "    df_related = clean_rawdf(df_related_raw)\n",
    "    related_dict = create_related_dict(df_related)\n",
    "    df_author_raw = pd.read_excel(filepath, 'author', engine='openpyxl')\n",
    "    df_author = clean_rawdf(df_author_raw)\n",
    "    author_dict = create_author_dict(df_author)\n",
    "    df_definedTerm_raw = pd.read_excel(filepath, 'definedTerms', engine='openpyxl')\n",
    "    df_dt = clean_rawdf(df_definedTerm_raw)\n",
    "    dfdt_dict = generate_dt_dict(df_dt)\n",
    "    df_distro_raw = pd.read_excel(filepath, 'distribution', engine='openpyxl')\n",
    "    df_distro = clean_rawdf(df_distro_raw)\n",
    "    distro_dict = create_distro_dict(df_distro)\n",
    "    base_dict_array = df_clean.to_dict(orient='records')\n",
    "    base_dict_array = clean_dict_array(base_dict_array)\n",
    "    for eachdict in base_dict_array:\n",
    "        url = eachdict['url']\n",
    "        eachdict['@context'] = context_dict\n",
    "        eachdict['funding'] = funding_dict[url]\n",
    "        eachdict['author'] = author_dict[url]\n",
    "        try:\n",
    "            eachdict['collectionSize'] = collection_dict[url]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            eachdict['distribution'] = distro_dict[url]\n",
    "        except:\n",
    "            pass\n",
    "        eachdict.update(related_dict[url])\n",
    "        eachdict.update(dfdt_dict[url])\n",
    "        batchlist.append(eachdict)\n",
    "    return batchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3a64a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dict = {\"owl\": \"http://www.w3.org/2002/07/owl#\",\n",
    "                      \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "                      \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "                      \"schema\": \"http://schema.org/\",\n",
    "                      \"niaid\": \"https://discovery.biothings.io/view/niaid/\",\n",
    "                      \"nde\": \"https://discovery.biothings.io/view/nde/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f26b4b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WormBase\n"
     ]
    }
   ],
   "source": [
    "batchlist = process_records(filepath,context_dict)\n",
    "today = datetime.now()\n",
    "with open(os.path.join(result_path,f'{today.strftime(\"%Y-%m-%d\")}_batch_file.json'),'w') as outfile:\n",
    "    outfile.write(json.dumps(batchlist, indent=4))\n",
    "print(batchlist[0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80c5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c03bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2083cca",
   "metadata": {},
   "source": [
    "### test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d86be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_dict = {}\n",
    "funding_grouped = df_funding.groupby(['url','identifier']).size().reset_index(name='counts')\n",
    "multi_funder_ids = funding_grouped.loc[funding_grouped['counts']>1]['identifier'].unique().tolist()\n",
    "single_funder_ids = funding_grouped.loc[funding_grouped['counts']==1]['identifier'].unique().tolist()\n",
    "single_funders = df_funding.loc[df_funding['identifier'].isin(single_funder_ids)].copy()\n",
    "urllist = df_funding['url'].unique().tolist()\n",
    "single_funders['temp'] = single_funders.apply(lambda row: process_single_funder(row), axis=1)\n",
    "funder_array = process_multi_funders(df_funding, multi_funder_ids)\n",
    "for eachurl in urllist:\n",
    "    funding_array = []\n",
    "    ## get all single funding objects and add to array\n",
    "    clean_singles = single_funders['temp'].loc[single_funders['url']==eachurl].tolist()\n",
    "    ## add any multi funding objects to the array\n",
    "    clean_multi= funder_array['temp'].loc[funder_array['url']==eachurl].tolist()\n",
    "    clean_singles.extend(clean_multi)\n",
    "    ## add the funding array to the funding_dict\n",
    "    funding_dict[eachurl]=clean_singles\n",
    "\n",
    "print(funding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f36cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
